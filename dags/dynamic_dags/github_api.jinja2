from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task, task_group
from airflow.exceptions import (
    AirflowException,
    AirflowBadRequest,
    AirflowNotFoundException,
    AirflowFailException
)
from airflow.utils.trigger_rule import TriggerRule
from datetime import datetime
from datetime import timedelta

from dags.plugins.common import deep_get
from dags.plugins.file_ops import load_as_json
from dags.plugins.github_api import get_request

import requests
import logging
import json


@task(trigger_rule=TriggerRule.ONE_FAILED, retries=1)
def extract(kind, url, params=None):
    return get_request(kind=kind, url=url, params=params)


@task
def transform(kind, columns, response):
    logging.info(f"[{{ dag_id }}:{kind}] 데이터 변환 시작")
    return [{new_col: deep_get(item, old_col) for new_col, old_col in columns.items()} for item in response.get('items', [])]


@task
def load(kind, content):
    dag_root_path = os.path.dirname(os.path.abspath(__file__))
    load_as_json(dag_root_path, kind, content)


@task_group
def get_data():
    tasks = {{ tasks }}
    result = {}
    for task in tasks:
        kind = task.get('name')
        try:
            if 'columns' in task:
                result[kind] = transform(kind=kind, columns=task.get('columns'), reponse=extract(kind=kind, url=task.get('url'), params=task.get('params')))
            else:
                result[kind] = extract(kind=kind, url=task.get('url'), params=task.get('params'))
        except Exception as e:
            logging.error(f"[{{ dag_id }}:{kind}] 데이터 수집 실패\\n" + repr(e))
            result[kind] = None
    return result


with DAG(
    dag_id="github_{{ dag_id }}",
    start_date=datetime(2023, 6, 15),
    schedule='{{ schedule }}',
    catchup={{ catchup or True }}
) as dag:
    load(kind={{ dag_id }}, content=get_data())