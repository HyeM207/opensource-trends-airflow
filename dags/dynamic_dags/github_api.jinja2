from airflow import DAG
from airflow.models import Variable
from airflow.decorators import task, task_group
from airflow.exceptions import (
    AirflowException,
    AirflowBadRequest,
    AirflowNotFoundException,
    AirflowFailException
)
from airflow.utils.trigger_rule import TriggerRule
from datetime import datetime, timezone
from plugins.slack import SlackAlert

import requests
import logging
import json
import os



def send_slack_message():
    from plugins.awsfunc import awsfunc

    s3_handler = awsfunc('secretsmanager')
    slack_token = s3_handler.getapikey(secret_id="slack-token")
    slack_alert = SlackAlert(channel="#monitoring_airflow", token=slack_token)
    return slack_alert


@task(trigger_rule=TriggerRule.ONE_FAILED, retries=1, pool="api_pool")
def extract(kind, url, params=None):
    from plugins.github_api import get_request

    response = get_request(kind=kind, url=url, params=params)      
    if isinstance(response, dict):
        if kind.startswith('language'): # info의 language
            response = [{"LANG_NM": key, "LANG_BYTE": value} for key, value in response.items()]
            return response
        else:
            return response.get('items', [])
    elif isinstance(response, list):
        return response
    else:
        logging.error("올바르지 않은 응답 형식")
        return []

{% if dag_id == "metric" %}
@task
def transform(kind, columns, response, repo_id):
    """
    ## metric만 별도임
    """
    from plugins.common import deep_get
    
    logging.info(f"[{{ dag_id }}:{kind}] 데이터 변환 시작")
    transformed_data = []
    for res in response:
        transformed_item = {}
        for new_col, old_col in columns.items():
            if not old_col.startswith("weeks"):
                value = deep_get(res, old_col)
            transformed_item[new_col] = value 
            transformed_item['REPO_ID'] = repo_id
        
        # week 정보만 따로 변형
        for week in res.get("weeks") :
            week_item = {}
            week_item["WEEK_UTC"] = week.get("w") 
            week_item["ADD_CNT"] = week.get("a") 
            week_item["DEL_CNT"] = week.get("d") 
            week_item["COMMIT_CNT"] = week.get("c")
            week_item.update(transformed_item)
            transformed_data.append(week_item)

    return transformed_data
{% elif  dag_id in ("repo", "meta") %}
@task
def transform(kind, columns, response):
    from plugins.common import deep_get
    
    logging.info(f"[{{ dag_id }}:{kind}] 데이터 변환 시작")
    return [{new_col: deep_get(item, old_col) for new_col, old_col in columns.items()} for item in response]
{% else %}
@task
def transform(kind, columns, response, repo_id):
    from plugins.common import deep_get
    
    logging.info(f"[detail:{kind}] 데이터 변환 시작")
    transformed_data = []
    for item in response:
        transformed_item = {}
        for new_col, old_col in columns.items():
            value = deep_get(item, old_col)
            transformed_item[new_col] = value
            transformed_item['REPO_ID'] = repo_id # repo_id 추가
        transformed_data.append(transformed_item)
    
    return transformed_data
{% endif %}


@task
def check(kind, data_list: list, valid_check: dict):
    from plugins.common import check_data
    
    logging.info(f"[{{ dag_id }}:{kind}] 데이터 값 검증 시작")
    data = check_data(kind=kind, data_list=data_list, valid_check=valid_check)
    checked_data = data.get('checked_data', [])
    error_data = data.get('error_data', [])
    if len(error_data) > 0:
        send_slack_message().fail_alert(context=error_data)
        return checked_data
    else:
        return checked_data


@task
def load(kind, content, repo=None):
    from plugins.awsfunc import awsfunc
    from plugins.file_ops import load_as_json

    utc_now = datetime.now(timezone.utc)
    time_str = utc_now.strftime("%Y-%m-%d_%H-%M-%S")
    date_str = utc_now.strftime("%Y/%m/%d")

    s3_handler = awsfunc('s3')
    bucket_name = "de-2-2"
    file_key = f"raw/github/{{ dag_id }}/{date_str}/{time_str}.json"

    logging.info(f"[{{ dag_id }}:{kind}] 데이터 저장 시작")
    s3_handler.ec2tos3(json.dumps(content), bucket_name, file_key)


{% if dag_id == "repo" %}
@task
def _delete_all_repo_from_redis():
    from plugins.redis_api import delete_all_repo_from_redis
    
    try:
        delete_all_repo_from_redis()
    except Exception as e:
        logging.error(f"레파지토리 정보 Redis 삭제 실패 {e}")

@task 
def _save_repo_to_redis(content):
    from plugins.redis_api import save_repo_to_redis, delete_all_repo_from_redis

    try:
        delete_all_repo_from_redis()
        for repo in content:
            _id = repo.get('ID')
            full_nm = repo.get('FULL_NM')
            if _id and full_nm:
                save_repo_to_redis(_id, full_nm)
            else:
                logging.error("레파지토리 ID 또는 FULL_NM 누락")
    except Exception as e:
        logging.error(f"레파지토리 정보 Redis 저장 실패 {e}")
{% endif %}

@task
def remove_duplicates(content):
    unique_items = []
    item_keys = set()

    for value in content.values():
        for item in value:
            item_id = item['ID']
            if item_id not in item_keys:
                unique_items.append(item)
                item_keys.add(item_id)
    return unique_items

{% if dag_id in ("repo", "meta") %}
@task_group
def getData():
{% else %}
@task_group
def getData(repo_fullnm, repo_id):
{% endif %}
    result = {}
    tasks = {{ tasks }}
    for kind, task in tasks.items():
        {% if dag_id in ("repo", "meta") %}
        url = task['url']
        {% else %}
        url = task['url'].format(FULL_NM=repo_fullnm)
        {% endif %}
        try:
            if kind.startswith('language'):
                data = extract(kind=kind, url=url, params=task.get('params'))
            elif 'columns' in task:
                {% if dag_id in ("repo", "meta") %}
                data = transform(kind=kind, columns=task.get('columns'), response=extract(kind=kind, url=url, params=task.get('params')))
                {% else %}
                data = transform(kind=kind, columns=task.get('columns'), response=extract(kind=kind, url=url, params=task.get('params')), repo_id=repo_id)
                {% endif %}
            else:
                data = extract(kind=kind, url=url, params=task.get('params'))
            if 'check' in task:
                result[kind] = check(kind=kind, data_list=data, valid_check=task['check'])
            else:
                result[kind] = data
        except Exception as e:
            logging.error(f"[{{ dag_id }}:{kind}] 데이터 수집 실패\\n" + repr(e))
            result[kind] = None
    {% if dag_id == "repo" %}
    result = remove_duplicates(result)
    _delete_all_repo_from_redis()
    _save_repo_to_redis(result)
    {% endif %}
    return result


with DAG(
    dag_id="github_{{ dag_id }}",
    start_date=datetime(2023, 8, 29),
    # schedule='{{ schedule }}',
    schedule=None,
    catchup={{ catchup }},
    on_success_callback=send_slack_message().success_alert,
    on_failure_callback=send_slack_message().fail_alert,
    concurrency = 90, 
    max_active_runs = {{ max_active_runs }} 
) as dag:
    {% if dag_id not in ("repo", "meta") %}
    from plugins.redis_api import get_all_repo_data_from_redis
    all_data = {}

    repositories = get_all_repo_data_from_redis()
    for repo_info in repositories.values():
        repo_id = repo_info.get("ID")
        data = getData(repo_info.get("FULL_NM"), repo_id=repo_id)
        if data:
            all_data[repo_id] = data
    
    load(kind="{{ dag_id }}", content=all_data)
    {% else %}
    load(kind="{{ dag_id }}", content=getData())
    {% endif %}
